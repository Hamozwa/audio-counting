{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa3970fc",
   "metadata": {},
   "source": [
    "# audio_get\n",
    "\n",
    "Retrieve and visualise spectrogram for audio exemplars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8839ff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from scipy import signal\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from data_converter import DataConverter\n",
    "import shutil\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "def convert_mp4_to_wav_moviepy(input_file, output_file):\n",
    "    clip = VideoFileClip(input_file)\n",
    "    clip.audio.write_audiofile(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74290d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get countix av video\n",
    "\n",
    "#item = \"0rvWeDPPQ3M_000007_000017\" #3\n",
    "\n",
    "# item = \"8re8pXSK_RQ_000006_000016\" #7\n",
    "\n",
    "# item = \"-4-17eFSRIE_000056_000066\" #6\n",
    "\n",
    "# item = \"1rPcLAUerQg_000021_000031\" #7\n",
    "\n",
    "# item = \"3oWUewKpaCA_000031_000041\" #3\n",
    "\n",
    "# item = \"-MrqXdoqCSI_000000_000010\" #5\n",
    "\n",
    "# item = \"1C9bH7JisIk_000004_000014\" #6\n",
    "\n",
    "item = \"B9tPbJrO6Oc_000005_000015\" #5\n",
    "\n",
    "input_file = f\"/datasets/Kinetics700-2020/test/Kinetics700-2020-test/{item}.mp4\"\n",
    "output_file = f\"{item}.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f675c5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1C9bH7JisIk_000004_000014.mp4'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copy(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8525597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-Tok_g_jgE0.wav'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get extreme countix av\n",
    "\n",
    "# item = \"624rDx0cR_Y.00\"\n",
    "# category = \"cluttered background\"\n",
    "\n",
    "# item = \"uby2dcP6cmw\"\n",
    "# category = \"cluttered background\"\n",
    "\n",
    "item = \"-Tok_g_jgE0\" #12\n",
    "category = \"out of view movement\"\n",
    "\n",
    "# item = \"Zd4YteIMwWY\" #4\n",
    "# category = \"out of view movement\"\n",
    "\n",
    "# item = \"6d_RTzFfQUE\" #3\n",
    "# category = \"out of view movement\"\n",
    "\n",
    "output_file = f\"{item}.wav\"\n",
    "\n",
    "shutil.copy(f\"/scratch/local/ssd/hani/ExtremeCountixAV/Audio/{category}/{item}.wav\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95abef6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'speech-us-gov-0193.wav'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get musan audio\n",
    "\n",
    "#folder = \"/scratch/local/ssd/hani/musan/music/hd-classical\"\n",
    "#folder = \"/scratch/local/ssd/hani/musan/music/jamendo\"\n",
    "folder = \"/scratch/local/ssd/hani/musan/speech/us-gov\"\n",
    "\n",
    "item = random.choice(os.listdir(folder))\n",
    "output_file = f\"{item}\"\n",
    "shutil.copy(f\"{folder}/{item}\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d939249",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to open the input \"-YfNn5IqE_4_000038_000048.mp4\" (No such file or directory).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#VISUALISE SOUND AS SPECTROGRAM\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m waveform, sr = \u001b[43mtorchaudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m waveform = waveform.mean(dim=\u001b[32m0\u001b[39m).numpy()\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(waveform.shape, sr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch/lib/python3.12/site-packages/torchaudio/_backend/utils.py:205\u001b[39m, in \u001b[36mget_load_func.<locals>.load\u001b[39m\u001b[34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[32m    129\u001b[39m \n\u001b[32m    130\u001b[39m \u001b[33;03mBy default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    202\u001b[39m \u001b[33;03m        `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    204\u001b[39m backend = dispatcher(uri, \u001b[38;5;28mformat\u001b[39m, backend)\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch/lib/python3.12/site-packages/torchaudio/_backend/ffmpeg.py:297\u001b[39m, in \u001b[36mFFmpegBackend.load\u001b[39m\u001b[34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\n\u001b[32m    289\u001b[39m     uri: InputType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    295\u001b[39m     buffer_size: \u001b[38;5;28mint\u001b[39m = \u001b[32m4096\u001b[39m,\n\u001b[32m    296\u001b[39m ) -> Tuple[torch.Tensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch/lib/python3.12/site-packages/torchaudio/_backend/ffmpeg.py:88\u001b[39m, in \u001b[36mload_audio\u001b[39m\u001b[34m(src, frame_offset, num_frames, convert, channels_first, format, buffer_size)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(src, \u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33mvorbis\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     87\u001b[39m     \u001b[38;5;28mformat\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mogg\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m s = \u001b[43mtorchaudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mStreamReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m sample_rate = \u001b[38;5;28mint\u001b[39m(s.get_src_stream_info(s.default_audio_stream).sample_rate)\n\u001b[32m     90\u001b[39m \u001b[38;5;28mfilter\u001b[39m = _get_load_filter(frame_offset, num_frames, convert)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch/lib/python3.12/site-packages/torio/io/_streaming_media_decoder.py:526\u001b[39m, in \u001b[36mStreamingMediaDecoder.__init__\u001b[39m\u001b[34m(self, src, format, option, buffer_size)\u001b[39m\n\u001b[32m    524\u001b[39m     \u001b[38;5;28mself\u001b[39m._be = ffmpeg_ext.StreamingMediaDecoderFileObj(src, \u001b[38;5;28mformat\u001b[39m, option, buffer_size)\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m     \u001b[38;5;28mself\u001b[39m._be = \u001b[43mffmpeg_ext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mStreamingMediaDecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moption\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    528\u001b[39m i = \u001b[38;5;28mself\u001b[39m._be.find_best_audio_stream()\n\u001b[32m    529\u001b[39m \u001b[38;5;28mself\u001b[39m._default_audio_stream = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m i < \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m i\n",
      "\u001b[31mRuntimeError\u001b[39m: Failed to open the input \"-YfNn5IqE_4_000038_000048.mp4\" (No such file or directory)."
     ]
    }
   ],
   "source": [
    "#VISUALISE SOUND AS SPECTROGRAM\n",
    "\n",
    "waveform, sr = torchaudio.load(output_file)\n",
    "waveform = waveform.mean(dim=0).numpy()\n",
    "print(waveform.shape, sr)\n",
    "_, _, spectrogram = signal.spectrogram(waveform, sr, nperseg=512, noverlap=256)\n",
    "\n",
    "mean = np.mean(spectrogram)\n",
    "std = np.std(spectrogram)\n",
    "spectrogram = np.divide(spectrogram - mean, std + 1e-9)\n",
    "\n",
    "data_converter = DataConverter()\n",
    "\n",
    "spectrogram = data_converter.apply_histogram_equalisation(spectrogram, method=\"global\")\n",
    "\n",
    "#visualise \n",
    "\n",
    "plt.figure(dpi=300, figsize=(10, 5))\n",
    "plt.imshow(spectrogram, aspect='auto', origin='lower', cmap='magma', interpolation='nearest')\n",
    "plt.ylabel('Frequency bins')\n",
    "plt.xlabel('Time frames')\n",
    "plt.colorbar(label='Intensity')\n",
    "plt.show()\n",
    "\n",
    "#rezise to 224x224\n",
    "\n",
    "_, _, spectrogram = signal.spectrogram(waveform, sr, nperseg=512, noverlap=256)\n",
    "\n",
    "mean = np.mean(spectrogram)\n",
    "std = np.std(spectrogram)\n",
    "spectrogram = np.divide(spectrogram - mean, std + 1e-9)\n",
    "\n",
    "data_converter = DataConverter()\n",
    "\n",
    "spectrogram = data_converter.apply_histogram_equalisation(spectrogram, method=\"global\")\n",
    "resized_spectrogram = cv2.resize(spectrogram, (224, 224), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "plt.figure(dpi=300, figsize=(5, 5))\n",
    "plt.imshow(resized_spectrogram, aspect='auto', origin='lower', cmap='magma', interpolation='nearest')\n",
    "plt.ylabel('Frequency bins')\n",
    "plt.xlabel('Time frames')\n",
    "plt.colorbar(label='Intensity')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
